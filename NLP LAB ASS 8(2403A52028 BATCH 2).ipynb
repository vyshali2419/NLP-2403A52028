{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfR22mI3a8JEMyE8Z7esem",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vyshali2419/NLP-2403A52028/blob/main/NLP%20LAB%20ASS%208(2403A52028%20BATCH%202).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat Lab8_NGram_Model_Vyshali_RollNo.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zVdydTB27R52",
        "outputId": "a1a1ce5b-c7ea-4597-edf9-0e123826153d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: Lab8_NGram_Model_Vyshali_RollNo.ipynb: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing\n",
        "import re\n",
        "import string\n",
        "\n",
        "# Tokenization and corpus utilities\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Counting and probability calculations\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# Numerical operations\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "onXvHZgF7s_S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset (replace with your own 1500+ word corpus if needed)\n",
        "corpus = \"\"\"\n",
        "Natural language processing enables computers to understand human language.\n",
        "Language models are widely used in speech recognition and text generation.\n",
        "N-gram models predict the next word based on previous words.\n",
        "Machine learning and NLP are important fields of artificial intelligence.\n",
        "Text data is growing rapidly due to social media and digital communication.\n",
        "\"\"\"\n",
        "\n",
        "# Display sample text\n",
        "print(\"Sample Text:\\n\")\n",
        "print(corpus[:300])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JJe5SE8K7wFS",
        "outputId": "08f5bfd3-005c-436f-8344-6c05654f9d6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Text:\n",
            "\n",
            "\n",
            "Natural language processing enables computers to understand human language.\n",
            "Language models are widely used in speech recognition and text generation.\n",
            "N-gram models predict the next word based on previous words.\n",
            "Machine learning and NLP are important fields of artificial intelligence.\n",
            "Text data is \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab') # Added to download the missing resource\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)  # remove numbers\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    sentences = sent_tokenize(text)\n",
        "    processed_sentences = []\n",
        "\n",
        "    for sent in sentences:\n",
        "        words = word_tokenize(sent)\n",
        "        words = [w for w in words if w not in stop_words]\n",
        "        words = ['<s>'] + words + ['</s>']\n",
        "        processed_sentences.append(words)\n",
        "\n",
        "    return processed_sentences\n",
        "\n",
        "processed_corpus = preprocess_text(corpus)\n",
        "print(processed_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DZKBG6Aq7zhr",
        "outputId": "fd62f760-43b6-471f-90b0-9de6db2b690c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['<s>', 'natural', 'language', 'processing', 'enables', 'computers', 'understand', 'human', 'language', 'language', 'models', 'widely', 'used', 'speech', 'recognition', 'text', 'generation', 'ngram', 'models', 'predict', 'next', 'word', 'based', 'previous', 'words', 'machine', 'learning', 'nlp', 'important', 'fields', 'artificial', 'intelligence', 'text', 'data', 'growing', 'rapidly', 'due', 'social', 'media', 'digital', 'communication', '</s>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_ngram(sentences, n):\n",
        "    ngrams = []\n",
        "    for sent in sentences:\n",
        "        for i in range(len(sent) - n + 1):\n",
        "            ngrams.append(tuple(sent[i:i+n]))\n",
        "    return Counter(ngrams)\n",
        "\n",
        "# Build models\n",
        "unigram = build_ngram(processed_corpus, 1)\n",
        "bigram = build_ngram(processed_corpus, 2)\n",
        "trigram = build_ngram(processed_corpus, 3)\n",
        "\n",
        "print(\"Unigram sample:\", list(unigram.items())[:5])\n",
        "print(\"Bigram sample:\", list(bigram.items())[:5])\n",
        "print(\"Trigram sample:\", list(trigram.items())[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "f54LMB8a8Dgj",
        "outputId": "965bc8ba-552b-4efa-cbc9-f6d3ad05d819"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram sample: [(('<s>',), 1), (('natural',), 1), (('language',), 3), (('processing',), 1), (('enables',), 1)]\n",
            "Bigram sample: [(('<s>', 'natural'), 1), (('natural', 'language'), 1), (('language', 'processing'), 1), (('processing', 'enables'), 1), (('enables', 'computers'), 1)]\n",
            "Trigram sample: [(('<s>', 'natural', 'language'), 1), (('natural', 'language', 'processing'), 1), (('language', 'processing', 'enables'), 1), (('processing', 'enables', 'computers'), 1), (('enables', 'computers', 'understand'), 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(unigram)\n",
        "\n",
        "def laplace_probability(ngram, ngram_counts, prev_counts):\n",
        "    return (ngram_counts[ngram] + 1) / (prev_counts + vocab_size)\n"
      ],
      "metadata": {
        "id": "vibGqDeL8FTa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_probability(sentence, n):\n",
        "    words = preprocess_text(sentence)[0]\n",
        "    prob = 1\n",
        "\n",
        "    if n == 1:\n",
        "        total = sum(unigram.values())\n",
        "        for w in words:\n",
        "            prob *= (unigram[(w,)] + 1) / (total + vocab_size)\n",
        "\n",
        "    elif n == 2:\n",
        "        for i in range(len(words)-1):\n",
        "            bg = (words[i], words[i+1])\n",
        "            prob *= laplace_probability(bg, bigram, unigram[(words[i],)])\n",
        "\n",
        "    elif n == 3:\n",
        "        for i in range(len(words)-2):\n",
        "            tg = (words[i], words[i+1], words[i+2])\n",
        "            prob *= laplace_probability(tg, trigram, bigram[(words[i], words[i+1])])\n",
        "\n",
        "    return prob\n",
        "\n",
        "sentences = [\n",
        "    \"language models are useful\",\n",
        "    \"natural language processing is important\",\n",
        "    \"machine learning uses data\",\n",
        "    \"text generation is challenging\",\n",
        "    \"artificial intelligence is growing\"\n",
        "]\n",
        "\n",
        "for s in sentences:\n",
        "    print(f\"\\nSentence: {s}\")\n",
        "    print(\"Unigram:\", sentence_probability(s,1))\n",
        "    print(\"Bigram:\", sentence_probability(s,2))\n",
        "    print(\"Trigram:\", sentence_probability(s,3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "u7wEvlxW8JSS",
        "outputId": "7d42d64e-4e57-41c3-be06-b2b25cb9649b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: language models are useful\n",
            "Unigram: 1.4648437500000005e-08\n",
            "Bigram: 8.22882722754353e-07\n",
            "Trigram: 1.7756942964699194e-05\n",
            "\n",
            "Sentence: natural language processing is important\n",
            "Unigram: 4.882812500000002e-10\n",
            "Bigram: 8.434273933050905e-08\n",
            "Trigram: 1.7745268445984731e-06\n",
            "\n",
            "Sentence: machine learning uses data\n",
            "Unigram: 1.2207031250000005e-10\n",
            "Bigram: 2.2750344161518885e-08\n",
            "Trigram: 4.6728797275524195e-07\n",
            "\n",
            "Sentence: text generation is challenging\n",
            "Unigram: 7.324218750000001e-09\n",
            "Bigram: 8.650818367417557e-07\n",
            "Trigram: 1.7756942964699194e-05\n",
            "\n",
            "Sentence: artificial intelligence is growing\n",
            "Unigram: 9.765625000000004e-09\n",
            "Bigram: 8.645130781377177e-07\n",
            "Trigram: 1.7756942964699194e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(sentence, n):\n",
        "    words = preprocess_text(sentence)[0]\n",
        "    N = len(words)\n",
        "    prob = sentence_probability(sentence, n)\n",
        "    return pow(1/prob, 1/N)\n",
        "\n",
        "for s in sentences:\n",
        "    print(f\"\\nSentence: {s}\")\n",
        "    print(\"Unigram Perplexity:\", perplexity(s,1))\n",
        "    print(\"Bigram Perplexity:\", perplexity(s,2))\n",
        "    print(\"Trigram Perplexity:\", perplexity(s,3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "v0-wl7ua8Owj",
        "outputId": "6a2c080c-6c64-4f13-f3b1-4c5015ca73ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: language models are useful\n",
            "Unigram Perplexity: 36.884316459269115\n",
            "Bigram Perplexity: 16.479059097001397\n",
            "Trigram Perplexity: 8.915102895753103\n",
            "\n",
            "Sentence: natural language processing is important\n",
            "Unigram Perplexity: 35.63594872561357\n",
            "Bigram Perplexity: 15.100525103118121\n",
            "Trigram Perplexity: 9.088374986375198\n",
            "\n",
            "Sentence: machine learning uses data\n",
            "Unigram Perplexity: 44.89848193237491\n",
            "Bigram Perplexity: 18.78604412915197\n",
            "Trigram Perplexity: 11.351917672117708\n",
            "\n",
            "Sentence: text generation is challenging\n",
            "Unigram Perplexity: 42.3689536419525\n",
            "Bigram Perplexity: 16.315055716842274\n",
            "Trigram Perplexity: 8.915102895753103\n",
            "\n",
            "Sentence: artificial intelligence is growing\n",
            "Unigram Perplexity: 40.00000000000001\n",
            "Bigram Perplexity: 16.317201869996897\n",
            "Trigram Perplexity: 8.915102895753103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hvaUCt3r8Szq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}